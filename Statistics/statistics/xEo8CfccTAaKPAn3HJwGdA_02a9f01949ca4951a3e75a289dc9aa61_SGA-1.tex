\documentclass[russian,12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[english,russian]{babel}
%\usepackage{amsbib}

\unitlength=1mm
\usepackage{graphicx} \graphicspath{{Images/}}
\textwidth=160mm \headheight=0mm \topmargin=0mm \textheight=215mm

\headheight=0cm \headsep=0cm \emergencystretch=5pt %\tolerance=100

\newcommand{\huh}{{\sl Доказательство. }}
\newcommand{\buh}{\hfill $\Box$} %\newcommand{\bbuh}{\hfill \Box}
\newcommand{\cov}{\mathop{\rm cov}\nolimits}

\newcommand{\sign}{\text{\rm sign\,}}


\newcommand{\De}{\Delta}\newcommand{\de}{\delta}
\newcommand{\eps}{\varepsilon}
\newcommand{\E}{\varnothing}
\newcommand{\btu}{\bigtriangleup} \newcommand{\doa}{^{\downarrow}}
\renewcommand{\le}{\leqslant} \renewcommand{\ge}{\geqslant} %Параллельная палка в нестрогом неравенстве
\newcommand{\ind}{\mathbb{I}} \newcommand{\Ind}{\mathbb{I}}
\newcommand{\Nat}{{\mathbb N}}\newcommand{\Int}{{\mathbb Z}}\newcommand{\Rat}{{\mathbb Q}}
\newcommand{\Real}{{\mathbb R}}
\newcommand{\BinFunc}{{\mathbb B}}
\newcommand{\Comp}{{\mathbb C}}

\newcommand{\bDg}{{\bf\Delta g}}\newcommand{\bDh}{{\bf\Delta h}}
\newcommand{\bDx}{{\bf\Delta x}}\newcommand{\bDy}{{\bf\Delta y}}
\newcommand{\be}{{\bf e}}\newcommand{\bE}{{\bf E}}
\newcommand{\bff}{{\bf f}} \newcommand{\bF}{{\bf F}}%{{\mathbb F}}
\newcommand{\bg}{{\bf g}}\newcommand{\bh}{{\bf h}}
\newcommand{\bi}{{\bf i}}\newcommand{\bk}{{\bf k}}
\newcommand{\bl}{{\bf l}} \newcommand{\bL}{\mathbb{L}}
\newcommand{\bn}{{\bf n}} \newcommand{\bOne}{{\bf 1}} \newcommand{\bZero}{{\bf 0}}
%\newcommand{\bP}[1]{{\bf P}\{#1\}}
\newcommand{\bPhi}{{\bf\Phi}} \newcommand{\bQ}{{\bf Q}}
\newcommand{\br}{{\bf r}} \newcommand{\bs}{{\bf s}}  \newcommand{\bS}{{\mathbb S}}
\newcommand{\bu}{\vec{\bf u}}
\newcommand{\bv}{{\bf v}} \newcommand{\bV}{{\bf V}}
%\newcommand{\bx}{{\bf x}} \newcommand{\by}{{\bf y}}
\newcommand{\bz}{{\bf z}} \newcommand{\bzx}{{\bf z_x}}

\newcommand{\cA}{{\cal A}} \newcommand{\cB}{{\cal B}}  \newcommand{\cD}{{\cal D}}
\newcommand{\cF}{{\cal F}}
\newcommand{\cG}{{\cal G}} \newcommand{\cH}{{\cal H}} \newcommand{\cK}{{\cal K}} \newcommand{\cL}{{\cal L}} \newcommand{\cM}{{\cal M}}
\newcommand{\cR}{{\cal R}}
\newcommand{\cO}{{\cal O}} \newcommand{\cS}{{\cal S}}  \newcommand{\cU}{{\cal U}}

\newcommand{\cX}{{\cal X}} \newcommand{\cY}{{\cal Y}} \newcommand{\cZ}{{\cal Z}}


\newtheorem{theor}{Теорема}
\newtheorem{coroll}{Следствие}[theor] %Льв.с.241
\newtheorem{lemma}[theor]{Лемма}
\newtheorem{lemma-theor}{Лемма}[theor] %лемма в доказательстве теоремы
\newtheorem{defin}{Определение}%

\sloppy

\begin{document}

{\bf Task 1}

To answer the questions, we have to analyse the data collection process that is
described in the task. First of all, we select respondents for our test. This is
usually can be considered as random selection from the some larger group of
people (e.g. all adults from 20 to 60 living in large cities, etc). Than we
measure the reaction time of each respondent under our four stimulus. The actual
reaction time obtained in one measurement can be modelled by random variable: if
we repeat the measurement (for the same respondent and the same stimulus), we
most likely get slighly different result. So we have to consider values $x_1,
x_2, x_3, x_4, x_5,\ldots$ as being generated by some random variables.
Properties of these random variables is what we are interested in.

First of all, we can argue that the distribution of reaction times can be
different for different people. It is possible that this distribution is
affected by some personal characteristics of respondents.
For example, it is possible that older respondents will have larger reaction
times on average than the younger ones, or larger variance of reaction times, or
smaller variance of reaction times, etc.

Note that we have several observations for each respondents, and they are placed
in the table in a particular order, so we know in advance that e.g. $x_1$ and
$x_2$ are related to the same respondent. 

We can model these observations in several possible ways. 

For example, we can say that for each respondent we have specific random
variable that models the distribution of reaction times of that specific
respondent. In this case observations $x_1, x_2, x_3, x_4$ can be modelled as
independent realizations of random variable $X_1$ (that corresponds to the first
respondent) and $x_5, x_6, x_7, x_8$ can be modelled as independent realizations
of random variable $X_2$.  Distributions of $X_1$ and $X_2$ can be different,
e.g. it is possible that $\mathbb EX_2 > \mathbb EX_1$, etc. 

On the other hand, we can say that all the observations are modelled with the
same random variable $X$. However, we have to take into account the fact that
reaction times of the same person (i.e. $x_1$ and $x_2$) can be closer
to each other than the reaction times of different persons (i.e. $x_1$
and $x_5$). In other words, if we see only the first row of the table and see
small value of $x_1$, and we know that $x_2$ is related to the same person as
$x_1$, then we can reasonable assume that $x_2$ is also small. For reaction
times of different respondents this can be not true. To take into account
this effect in our model, we have to assume that values $x_1$ and $x_2$, while
being sampled from the same random variable $X$ like all other reaction times in
our table, are correlated between each other (i.e. small values of $x_1$ makes
it more plausible to get small values of $x_2$).

Similar reasoning can be used to analyse $x_1$ and $x_5$: in this case we have
different respondents, but these values can be correlated due to the fact that
they correspond to the same stimulus. (I.e. it is possible to assume that
stimulus 1 lead to smaller reacted times on average across the whole population
than stimulus 2, etc.)

So the answers to questions 1 and 2 actually depend on the model that we impose.
In one model, we may assume that $x_1$ and $x_2$ (and $x_1$ and $x_5$) are
independent, but distribution of $x_1$ and $x_5$ are different. In another
model, we may assume that all the reaction times is obtained from the same
distribution, but $x_1$ and $x_2$ are correlated. In both cases, we cannot say
that $x_1, x_2, x_3, x_4, x_5 \ldots$ is an i.i.d. sample from some random
variable $X$: either independence violated (the second case), or they are not
identically distributed.

One should be cautios when analyse this kind of data.

\newpage

{\bf Task 2}

We want find an expression for $a$, which yields a minimum of function $\sum_{i=1}^n (X_i-a)^2 \to min$.
We can rewrite it in a following way:
$f(a)=\sum_{i=1}^n (X_i-a)^2=\sum_{i=1}^n X_i^2-2\sum_{i=1}^n aX_i+\sum_{i=1}^n a^2$. Minimizing this function can be done by differentiating it with respect to a and setting it to zero, to find extrema.

$$f'(a)=-2\sum_{i=1}^n X_i+\sum_{i=1}^n 2a=0$$

$$na=\sum_{i=1}^n X_i$$

So $a=\frac{\sum_{i=1}^n X_i}{n}={\bar X}$. It is the only extrema and the second derivative with respect to $a$ is  $\sum_{i=1}^n 2=2n>0$, so $a={\bar X}$ yields a minimum of our function.

Most frequent errors: 

1. Not checking that second derivative  > 0 (that $a={\bar X}$ really yields the minimum, not a maximum).

2. Consideration of the function as a function with respect to sample $X$.

\newpage

{\bf Task 3}

We sort the sample and then we have new random variables $(y_1,\ldots,y_n)$. It is not only changing the order of values, we have now new random variables, for example $y_1$ is a minumum of $(x_1,\ldots,x_n)$ and $y_n$ is a maximum.

For example, $y_2 \geq y_1$ and so its distributions are not the same as if it generated independently as $x_i$ before. And also it means that they are not independent.

Most frequent errors:

1. 'We change only order of values, so sample properties remain the same(mean, variance and so on)' - it is not true, for example, we can find cumulative distribution functions of $y_1$ and $y_n$ and we see that they are different:
$$F_{y_1}=F_x^n$$
$$F_{y_n}=1-(1-F_x)^n$$




\end{document}
